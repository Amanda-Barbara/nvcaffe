I0706 19:56:29.067651 10017 parallel.cpp:49] P2PManager::Init @ devy-PC
I0706 19:56:29.188709 10017 common.cpp:470] GPU 0 'GeForce MX250' has compute capability 6.1
I0706 19:56:30.635242 10017 caffe.cpp:703] This is NVCaffe 0.17.3 started at Tue Jul  6 19:56:29 2021
I0706 19:56:30.635573 10017 caffe.cpp:705] CuDNN version: 7600
I0706 19:56:30.635658 10017 caffe.cpp:706] CuBLAS version: 10200
I0706 19:56:30.635723 10017 caffe.cpp:707] CUDA version: 10010
I0706 19:56:30.635782 10017 caffe.cpp:708] CUDA driver version: 11020
I0706 19:56:30.635838 10017 caffe.cpp:709] Arguments: 
[0]: ./cmake-build-debug/tools/caffe-d
[1]: train
[2]: --solver=examples/mnist/lenet_solver.prototxt
I0706 19:56:30.651151 10017 caffe.cpp:216] Using GPUs 0
I0706 19:56:30.652299 10017 caffe.cpp:221] GPU 0: GeForce MX250
I0706 19:56:31.116508 10017 solver.cpp:40] Solver data type: FLOAT
I0706 19:56:31.118343 10017 gpu_memory.cpp:82] GPUMemory::Manager initialized
I0706 19:56:31.118458 10017 gpu_memory.cpp:84] Total memory: 2099904512, Free: 1766850560, dev_info[0]: total=2099904512 free=1766850560
I0706 19:56:31.119371 10017 common.cpp:135] [0] New Caffe instance 0x7fd9e5997750, count 1, thread 10017
I0706 19:56:31.119518 10017 common.cpp:194] New stream 0x560f08863690, device 0, thread 10017
I0706 19:56:31.169534 10017 solver.cpp:43] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I0706 19:56:31.170961 10017 solver.cpp:84] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0706 19:56:31.174185 10017 net.cpp:462] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0706 19:56:31.174440 10017 net.cpp:462] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0706 19:56:31.174942 10017 net.cpp:86] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0706 19:56:31.178272 10017 net.cpp:116] Using FLOAT as default forward math type
I0706 19:56:31.178498 10017 net.cpp:122] Using FLOAT as default backward math type
I0706 19:56:31.178573 10017 net.cpp:138] Setting types for Layer mnist
I0706 19:56:31.178683 10017 layer_factory.hpp:172] Creating layer 'mnist' of type 'Data'
I0706 19:56:31.178763 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:31.179443 10017 internal_thread.cpp:19] InternalThread 10017: BasePrefetchingDataLayer of local solver rank 0
I0706 19:56:31.179667 10017 internal_thread.cpp:19] InternalThread 10017: BatchTransformer of rank 0, queues 1
I0706 19:56:31.181612 10017 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:31.182790 10046 common.cpp:135] [0] New Caffe instance 0x7fd9c13a5610, count 2, thread 10046
I0706 19:56:31.183102 10046 common.cpp:194] New stream 0x7fd9ac000c40, device 0, thread 10046
I0706 19:56:31.186069 10046 internal_thread.cpp:85] Started internal thread 10046 on device 0, rank 0
I0706 19:56:31.186229 10046 batch_transformer.cpp:57] Started BatchTransformer thread 10046
I0706 19:56:31.186362 10046 blocking_queue.cpp:40] Data layer prefetch queue empty
I0706 19:56:31.186826 10017 net.cpp:205] Created Layer mnist (0)
I0706 19:56:31.187077 10017 net.cpp:547] mnist -> data
I0706 19:56:31.188308 10017 net.cpp:547] mnist -> label
I0706 19:56:31.189445 10017 internal_thread.cpp:19] InternalThread 10017: DataReader of local solver rank 0, parser threads 1, transf threads 1
I0706 19:56:31.189839 10017 data_reader.cpp:68] Sample Data Reader threads: 1, out queues: 1, depth: 64
I0706 19:56:31.190816 10017 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:31.191779 10047 common.cpp:135] [0] New Caffe instance 0x7fd9c0ba4610, count 3, thread 10047
I0706 19:56:31.192014 10047 common.cpp:194] New stream 0x7fd9a0000c40, device 0, thread 10047
I0706 19:56:31.194087 10047 internal_thread.cpp:85] Started internal thread 10047 on device 0, rank 0
I0706 19:56:31.194370 10047 db_lmdb.cpp:36] Opened lmdb examples/mnist/mnist_train_lmdb
I0706 19:56:31.199391 10047 common.cpp:159] [0] Caffe instance 0x7fd9c0ba4610 deleted, count 2, thread 10047
I0706 19:56:31.201086 10017 data_layer.cpp:199] [n0.d0.r0] Output data size: 64, 1, 28, 28
I0706 19:56:31.201731 10017 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:31.202459 10017 net.cpp:265] Setting up mnist
I0706 19:56:31.202601 10048 common.cpp:135] [0] New Caffe instance 0x7fd9a7fff610, count 3, thread 10048
I0706 19:56:31.202821 10048 common.cpp:194] New stream 0x7fd9a00023d0, device 0, thread 10048
I0706 19:56:31.204888 10048 internal_thread.cpp:85] Started internal thread 10048 on device 0, rank 0
I0706 19:56:31.204903 10017 net.cpp:272] TRAIN Top shape for layer 0 'mnist' 64 1 28 28 (50176)
I0706 19:56:31.205260 10017 net.cpp:272] TRAIN Top shape for layer 0 'mnist' 64 (64)
I0706 19:56:31.205511 10017 net.cpp:138] Setting types for Layer conv1
I0706 19:56:31.205626 10017 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'
I0706 19:56:31.205744 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:31.206501 10017 net.cpp:205] Created Layer conv1 (1)
I0706 19:56:31.206733 10017 net.cpp:577] conv1 <- data
I0706 19:56:31.207131 10017 net.cpp:547] conv1 -> conv1
I0706 19:56:31.211645 10017 common.cpp:194] New stream 0x560f0c963c60, device 0, thread 10017
I0706 19:56:35.155280 10017 cudnn_conv_layer.cpp:300] [n0.d0.r0] AllocateWorkspace trying to allocate 4194304 bytes for layer conv1
I0706 19:56:35.159056 10017 net.cpp:265] Setting up conv1
I0706 19:56:35.159271 10017 net.cpp:272] TRAIN Top shape for layer 1 'conv1' 64 20 24 24 (737280)
I0706 19:56:35.159972 10017 net.cpp:138] Setting types for Layer pool1
I0706 19:56:35.160135 10017 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'
I0706 19:56:35.160233 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.160604 10017 net.cpp:205] Created Layer pool1 (2)
I0706 19:56:35.160799 10017 net.cpp:577] pool1 <- conv1
I0706 19:56:35.160990 10017 net.cpp:547] pool1 -> pool1
I0706 19:56:35.161670 10017 net.cpp:265] Setting up pool1
I0706 19:56:35.161849 10017 net.cpp:272] TRAIN Top shape for layer 2 'pool1' 64 20 12 12 (184320)
I0706 19:56:35.162024 10017 net.cpp:138] Setting types for Layer conv2
I0706 19:56:35.162122 10017 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'
I0706 19:56:35.162206 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.162606 10017 net.cpp:205] Created Layer conv2 (3)
I0706 19:56:35.162741 10017 net.cpp:577] conv2 <- pool1
I0706 19:56:35.162900 10017 net.cpp:547] conv2 -> conv2
I0706 19:56:35.185865 10017 cudnn_conv_layer.cpp:300] [n0.d0.r0] AllocateWorkspace trying to allocate 4194304 bytes for layer conv2
I0706 19:56:35.186100 10017 net.cpp:265] Setting up conv2
I0706 19:56:35.186179 10017 net.cpp:272] TRAIN Top shape for layer 3 'conv2' 64 50 8 8 (204800)
I0706 19:56:35.186458 10017 net.cpp:138] Setting types for Layer pool2
I0706 19:56:35.186538 10017 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'
I0706 19:56:35.186609 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.186859 10017 net.cpp:205] Created Layer pool2 (4)
I0706 19:56:35.186975 10017 net.cpp:577] pool2 <- conv2
I0706 19:56:35.187129 10017 net.cpp:547] pool2 -> pool2
I0706 19:56:35.187587 10017 net.cpp:265] Setting up pool2
I0706 19:56:35.187685 10017 net.cpp:272] TRAIN Top shape for layer 4 'pool2' 64 50 4 4 (51200)
I0706 19:56:35.187795 10017 net.cpp:138] Setting types for Layer ip1
I0706 19:56:35.187855 10017 layer_factory.hpp:172] Creating layer 'ip1' of type 'InnerProduct'
I0706 19:56:35.187916 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.188174 10017 net.cpp:205] Created Layer ip1 (5)
I0706 19:56:35.188282 10017 net.cpp:577] ip1 <- pool2
I0706 19:56:35.188421 10017 net.cpp:547] ip1 -> ip1
I0706 19:56:35.545213 10017 net.cpp:265] Setting up ip1
I0706 19:56:35.545486 10017 net.cpp:272] TRAIN Top shape for layer 5 'ip1' 64 500 (32000)
I0706 19:56:35.545847 10017 net.cpp:138] Setting types for Layer relu1
I0706 19:56:35.545938 10017 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'
I0706 19:56:35.546015 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.546247 10017 net.cpp:205] Created Layer relu1 (6)
I0706 19:56:35.546360 10017 net.cpp:577] relu1 <- ip1
I0706 19:56:35.546519 10017 net.cpp:532] relu1 -> ip1 (in-place)
I0706 19:56:35.546725 10017 net.cpp:265] Setting up relu1
I0706 19:56:35.546792 10017 net.cpp:272] TRAIN Top shape for layer 6 'relu1' 64 500 (32000)
I0706 19:56:35.546888 10017 net.cpp:138] Setting types for Layer ip2
I0706 19:56:35.546947 10017 layer_factory.hpp:172] Creating layer 'ip2' of type 'InnerProduct'
I0706 19:56:35.547008 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.547163 10017 net.cpp:205] Created Layer ip2 (7)
I0706 19:56:35.547245 10017 net.cpp:577] ip2 <- ip1
I0706 19:56:35.547374 10017 net.cpp:547] ip2 -> ip2
I0706 19:56:35.552217 10017 net.cpp:265] Setting up ip2
I0706 19:56:35.552342 10017 net.cpp:272] TRAIN Top shape for layer 7 'ip2' 64 10 (640)
I0706 19:56:35.552520 10017 net.cpp:138] Setting types for Layer loss
I0706 19:56:35.552587 10017 layer_factory.hpp:172] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0706 19:56:35.552654 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.552917 10017 net.cpp:205] Created Layer loss (8)
I0706 19:56:35.553018 10017 net.cpp:577] loss <- ip2
I0706 19:56:35.553153 10017 net.cpp:577] loss <- label
I0706 19:56:35.553272 10017 net.cpp:547] loss -> loss
I0706 19:56:35.554637 10017 net.cpp:265] Setting up loss
I0706 19:56:35.554795 10017 net.cpp:272] TRAIN Top shape for layer 8 'loss' (1)
I0706 19:56:35.554973 10017 net.cpp:276]     with loss weight 1
I0706 19:56:35.555269 10017 net.cpp:341] loss needs backward computation.
I0706 19:56:35.555419 10017 net.cpp:341] ip2 needs backward computation.
I0706 19:56:35.555495 10017 net.cpp:341] relu1 needs backward computation.
I0706 19:56:35.555558 10017 net.cpp:341] ip1 needs backward computation.
I0706 19:56:35.555619 10017 net.cpp:341] pool2 needs backward computation.
I0706 19:56:35.555675 10017 net.cpp:341] conv2 needs backward computation.
I0706 19:56:35.555742 10017 net.cpp:341] pool1 needs backward computation.
I0706 19:56:35.555805 10017 net.cpp:341] conv1 needs backward computation.
I0706 19:56:35.555872 10017 net.cpp:343] mnist does not need backward computation.
I0706 19:56:35.555932 10017 net.cpp:385] This network produces output loss
I0706 19:56:35.556306 10017 net.cpp:408] Top memory (TRAIN) required for data: 5169928 diff: 5169928
I0706 19:56:35.556396 10017 net.cpp:411] Bottom memory (TRAIN) required for data: 5169920 diff: 5169920
I0706 19:56:35.556443 10017 net.cpp:414] Shared (in-place) memory (TRAIN) by data: 128000 diff: 128000
I0706 19:56:35.556488 10017 net.cpp:417] Parameters memory (TRAIN) required for data: 1724320 diff: 2320
I0706 19:56:35.556535 10017 net.cpp:420] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0706 19:56:35.556582 10017 net.cpp:426] Network initialization done.
I0706 19:56:35.559012 10017 solver.cpp:173] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0706 19:56:35.559626 10017 net.cpp:462] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0706 19:56:35.560017 10017 net.cpp:86] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0706 19:56:35.562351 10017 net.cpp:116] Using FLOAT as default forward math type
I0706 19:56:35.562448 10017 net.cpp:122] Using FLOAT as default backward math type
I0706 19:56:35.562512 10017 net.cpp:138] Setting types for Layer mnist
I0706 19:56:35.562568 10017 layer_factory.hpp:172] Creating layer 'mnist' of type 'Data'
I0706 19:56:35.562674 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.562955 10017 internal_thread.cpp:19] InternalThread 10017: BasePrefetchingDataLayer of local solver rank 0
I0706 19:56:35.563091 10017 internal_thread.cpp:19] InternalThread 10017: BatchTransformer of rank 0, queues 1
I0706 19:56:35.563321 10017 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:35.564196 10085 common.cpp:135] [0] New Caffe instance 0x7fd9a77fe610, count 4, thread 10085
I0706 19:56:35.564406 10085 common.cpp:194] New stream 0x7fd99c000c40, device 0, thread 10085
I0706 19:56:35.566434 10085 internal_thread.cpp:85] Started internal thread 10085 on device 0, rank 0
I0706 19:56:35.566525 10085 batch_transformer.cpp:57] Started BatchTransformer thread 10085
I0706 19:56:35.566504 10017 net.cpp:205] Created Layer mnist (0)
I0706 19:56:35.566721 10017 net.cpp:547] mnist -> data
I0706 19:56:35.566963 10017 net.cpp:547] mnist -> label
I0706 19:56:35.567236 10017 internal_thread.cpp:19] InternalThread 10017: DataReader of local solver rank 0, parser threads 1, transf threads 1
I0706 19:56:35.567346 10017 data_reader.cpp:68] Data Reader threads: 1, out queues: 1, depth: 100
I0706 19:56:35.567726 10017 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:35.568567 10086 common.cpp:135] [0] New Caffe instance 0x7fd9a647e610, count 5, thread 10086
I0706 19:56:35.568850 10086 common.cpp:194] New stream 0x7fd994000c40, device 0, thread 10086
I0706 19:56:35.570700 10086 internal_thread.cpp:85] Started internal thread 10086 on device 0, rank 0
I0706 19:56:35.570895 10086 db_lmdb.cpp:36] Opened lmdb examples/mnist/mnist_test_lmdb
I0706 19:56:35.571938 10017 data_layer.cpp:199] (n0.d0.r0) Output data size: 100, 1, 28, 28
I0706 19:56:35.572391 10017 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:35.573014 10017 net.cpp:265] Setting up mnist
I0706 19:56:35.573199 10017 net.cpp:272] TEST Top shape for layer 0 'mnist' 100 1 28 28 (78400)
I0706 19:56:35.573343 10017 net.cpp:272] TEST Top shape for layer 0 'mnist' 100 (100)
I0706 19:56:35.573413 10087 common.cpp:135] [0] New Caffe instance 0x7fd9a4c7d610, count 6, thread 10087
I0706 19:56:35.573601 10087 common.cpp:194] New stream 0x7fd998000c40, device 0, thread 10087
I0706 19:56:35.575896 10087 internal_thread.cpp:85] Started internal thread 10087 on device 0, rank 0
I0706 19:56:35.575958 10017 net.cpp:138] Setting types for Layer label_mnist_1_split
I0706 19:56:35.576156 10087 data_layer.cpp:105] (n0.d0.r0) Parser threads: 1
I0706 19:56:35.576285 10017 layer_factory.hpp:172] Creating layer 'label_mnist_1_split' of type 'Split'
I0706 19:56:35.576310 10087 data_layer.cpp:107] (n0.d0.r0) Transformer threads: 1
I0706 19:56:35.576481 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.576809 10017 net.cpp:205] Created Layer label_mnist_1_split (1)
I0706 19:56:35.576921 10017 net.cpp:577] label_mnist_1_split <- label
I0706 19:56:35.577123 10017 net.cpp:547] label_mnist_1_split -> label_mnist_1_split_0
I0706 19:56:35.577338 10017 net.cpp:547] label_mnist_1_split -> label_mnist_1_split_1
I0706 19:56:35.577914 10017 net.cpp:265] Setting up label_mnist_1_split
I0706 19:56:35.578016 10017 net.cpp:272] TEST Top shape for layer 1 'label_mnist_1_split' 100 (100)
I0706 19:56:35.578117 10017 net.cpp:272] TEST Top shape for layer 1 'label_mnist_1_split' 100 (100)
I0706 19:56:35.578207 10017 net.cpp:138] Setting types for Layer conv1
I0706 19:56:35.578269 10017 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'
I0706 19:56:35.578332 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.578653 10017 net.cpp:205] Created Layer conv1 (2)
I0706 19:56:35.578755 10017 net.cpp:577] conv1 <- data
I0706 19:56:35.578963 10017 net.cpp:547] conv1 -> conv1
I0706 19:56:35.581555 10017 cudnn_conv_layer.cpp:300] (n0.d0.r0) AllocateWorkspace trying to allocate 4194304 bytes for layer conv1
I0706 19:56:35.581795 10017 net.cpp:265] Setting up conv1
I0706 19:56:35.581869 10017 net.cpp:272] TEST Top shape for layer 2 'conv1' 100 20 24 24 (1152000)
I0706 19:56:35.582172 10017 net.cpp:138] Setting types for Layer pool1
I0706 19:56:35.582262 10017 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'
I0706 19:56:35.582357 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.582649 10017 net.cpp:205] Created Layer pool1 (3)
I0706 19:56:35.582780 10017 net.cpp:577] pool1 <- conv1
I0706 19:56:35.582932 10017 net.cpp:547] pool1 -> pool1
I0706 19:56:35.583458 10017 net.cpp:265] Setting up pool1
I0706 19:56:35.583600 10017 net.cpp:272] TEST Top shape for layer 3 'pool1' 100 20 12 12 (288000)
I0706 19:56:35.583726 10017 net.cpp:138] Setting types for Layer conv2
I0706 19:56:35.583787 10017 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'
I0706 19:56:35.583849 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.584224 10017 net.cpp:205] Created Layer conv2 (4)
I0706 19:56:35.584339 10017 net.cpp:577] conv2 <- pool1
I0706 19:56:35.584484 10017 net.cpp:547] conv2 -> conv2
I0706 19:56:35.590845 10085 common.cpp:194] New stream 0x7fd99c0022d0, device 0, thread 10085
I0706 19:56:35.592787 10085 common.cpp:194] New stream 0x7fd99c002980, device 0, thread 10085
I0706 19:56:35.613214 10017 cudnn_conv_layer.cpp:300] (n0.d0.r0) AllocateWorkspace trying to allocate 4194304 bytes for layer conv2
I0706 19:56:35.613432 10017 net.cpp:265] Setting up conv2
I0706 19:56:35.613517 10017 net.cpp:272] TEST Top shape for layer 4 'conv2' 100 50 8 8 (320000)
I0706 19:56:35.613835 10017 net.cpp:138] Setting types for Layer pool2
I0706 19:56:35.613926 10017 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'
I0706 19:56:35.614003 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.614233 10017 net.cpp:205] Created Layer pool2 (5)
I0706 19:56:35.614337 10017 net.cpp:577] pool2 <- conv2
I0706 19:56:35.614498 10017 net.cpp:547] pool2 -> pool2
I0706 19:56:35.615132 10017 net.cpp:265] Setting up pool2
I0706 19:56:35.615252 10017 net.cpp:272] TEST Top shape for layer 5 'pool2' 100 50 4 4 (80000)
I0706 19:56:35.615375 10017 net.cpp:138] Setting types for Layer ip1
I0706 19:56:35.615435 10017 layer_factory.hpp:172] Creating layer 'ip1' of type 'InnerProduct'
I0706 19:56:35.615499 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.615675 10017 net.cpp:205] Created Layer ip1 (6)
I0706 19:56:35.615770 10017 net.cpp:577] ip1 <- pool2
I0706 19:56:35.615957 10017 net.cpp:547] ip1 -> ip1
I0706 19:56:35.931915 10017 net.cpp:265] Setting up ip1
I0706 19:56:35.932178 10017 net.cpp:272] TEST Top shape for layer 6 'ip1' 100 500 (50000)
I0706 19:56:35.932634 10017 net.cpp:138] Setting types for Layer relu1
I0706 19:56:35.932744 10017 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'
I0706 19:56:35.932826 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.933023 10017 net.cpp:205] Created Layer relu1 (7)
I0706 19:56:35.933125 10017 net.cpp:577] relu1 <- ip1
I0706 19:56:35.933279 10017 net.cpp:532] relu1 -> ip1 (in-place)
I0706 19:56:35.933445 10017 net.cpp:265] Setting up relu1
I0706 19:56:35.933516 10017 net.cpp:272] TEST Top shape for layer 7 'relu1' 100 500 (50000)
I0706 19:56:35.933706 10017 net.cpp:138] Setting types for Layer ip2
I0706 19:56:35.933779 10017 layer_factory.hpp:172] Creating layer 'ip2' of type 'InnerProduct'
I0706 19:56:35.933845 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.934057 10017 net.cpp:205] Created Layer ip2 (8)
I0706 19:56:35.934151 10017 net.cpp:577] ip2 <- ip1
I0706 19:56:35.934293 10017 net.cpp:547] ip2 -> ip2
I0706 19:56:35.939296 10017 net.cpp:265] Setting up ip2
I0706 19:56:35.939468 10017 net.cpp:272] TEST Top shape for layer 8 'ip2' 100 10 (1000)
I0706 19:56:35.939707 10017 net.cpp:138] Setting types for Layer ip2_ip2_0_split
I0706 19:56:35.939771 10017 layer_factory.hpp:172] Creating layer 'ip2_ip2_0_split' of type 'Split'
I0706 19:56:35.939836 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.940022 10017 net.cpp:205] Created Layer ip2_ip2_0_split (9)
I0706 19:56:35.940196 10017 net.cpp:577] ip2_ip2_0_split <- ip2
I0706 19:56:35.940400 10017 net.cpp:547] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0706 19:56:35.940640 10017 net.cpp:547] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0706 19:56:35.941160 10017 net.cpp:265] Setting up ip2_ip2_0_split
I0706 19:56:35.941270 10017 net.cpp:272] TEST Top shape for layer 9 'ip2_ip2_0_split' 100 10 (1000)
I0706 19:56:35.941367 10017 net.cpp:272] TEST Top shape for layer 9 'ip2_ip2_0_split' 100 10 (1000)
I0706 19:56:35.941458 10017 net.cpp:138] Setting types for Layer accuracy
I0706 19:56:35.941519 10017 layer_factory.hpp:172] Creating layer 'accuracy' of type 'Accuracy'
I0706 19:56:35.941581 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.941799 10017 net.cpp:205] Created Layer accuracy (10)
I0706 19:56:35.941895 10017 net.cpp:577] accuracy <- ip2_ip2_0_split_0
I0706 19:56:35.942032 10017 net.cpp:577] accuracy <- label_mnist_1_split_0
I0706 19:56:35.942137 10017 net.cpp:547] accuracy -> accuracy
I0706 19:56:35.942348 10017 net.cpp:265] Setting up accuracy
I0706 19:56:35.942431 10017 net.cpp:272] TEST Top shape for layer 10 'accuracy' (1)
I0706 19:56:35.942526 10017 net.cpp:138] Setting types for Layer loss
I0706 19:56:35.942584 10017 layer_factory.hpp:172] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0706 19:56:35.942644 10017 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0706 19:56:35.942828 10017 net.cpp:205] Created Layer loss (11)
I0706 19:56:35.942950 10017 net.cpp:577] loss <- ip2_ip2_0_split_1
I0706 19:56:35.943143 10017 net.cpp:577] loss <- label_mnist_1_split_1
I0706 19:56:35.943307 10017 net.cpp:547] loss -> loss
I0706 19:56:35.944638 10017 net.cpp:265] Setting up loss
I0706 19:56:35.944762 10017 net.cpp:272] TEST Top shape for layer 11 'loss' (1)
I0706 19:56:35.944844 10017 net.cpp:276]     with loss weight 1
I0706 19:56:35.944957 10017 net.cpp:341] loss needs backward computation.
I0706 19:56:35.945051 10017 net.cpp:343] accuracy does not need backward computation.
I0706 19:56:35.945124 10017 net.cpp:341] ip2_ip2_0_split needs backward computation.
I0706 19:56:35.945183 10017 net.cpp:341] ip2 needs backward computation.
I0706 19:56:35.945242 10017 net.cpp:341] relu1 needs backward computation.
I0706 19:56:35.945297 10017 net.cpp:341] ip1 needs backward computation.
I0706 19:56:35.945367 10017 net.cpp:341] pool2 needs backward computation.
I0706 19:56:35.945459 10017 net.cpp:341] conv2 needs backward computation.
I0706 19:56:35.945559 10017 net.cpp:341] pool1 needs backward computation.
I0706 19:56:35.945648 10017 net.cpp:341] conv1 needs backward computation.
I0706 19:56:35.945765 10017 net.cpp:343] label_mnist_1_split does not need backward computation.
I0706 19:56:35.945879 10017 net.cpp:343] mnist does not need backward computation.
I0706 19:56:35.945932 10017 net.cpp:385] This network produces output accuracy
I0706 19:56:35.946025 10017 net.cpp:385] This network produces output loss
I0706 19:56:35.946329 10017 net.cpp:408] Top memory (TEST) required for data: 8086816 diff: 8086816
I0706 19:56:35.946399 10017 net.cpp:411] Bottom memory (TEST) required for data: 8086800 diff: 8086800
I0706 19:56:35.946446 10017 net.cpp:414] Shared (in-place) memory (TEST) by data: 200000 diff: 200000
I0706 19:56:35.946492 10017 net.cpp:417] Parameters memory (TEST) required for data: 1724320 diff: 2320
I0706 19:56:35.946538 10017 net.cpp:420] Parameters shared memory (TEST) by data: 0 diff: 0
I0706 19:56:35.946583 10017 net.cpp:426] Network initialization done.
I0706 19:56:35.947090 10017 solver.cpp:54] Solver scaffolding done.
I0706 19:56:35.949139 10017 caffe.cpp:250] Starting Optimization
I0706 19:56:35.949273 10017 solver.cpp:411] [0.0] Solving LeNet Learning Rate Policy: inv
I0706 19:56:35.949846 10017 net.cpp:1424] [0.0] Reserving 1725184 bytes of shared learnable space for type FLOAT
I0706 19:56:35.955384 10017 solver.cpp:236] Initial Test started...
I0706 19:56:35.955648 10017 solver.cpp:494] Iteration 0, Testing net (#0)
I0706 19:56:35.955770 10017 net.cpp:1073] Copying source layer mnist
I0706 19:56:35.955824 10017 net.cpp:1073] Copying source layer conv1
I0706 19:56:35.956168 10017 net.cpp:1073] Copying source layer pool1
I0706 19:56:35.956246 10017 net.cpp:1073] Copying source layer conv2
I0706 19:56:35.956507 10017 net.cpp:1073] Copying source layer pool2
I0706 19:56:35.956629 10017 net.cpp:1073] Copying source layer ip1
I0706 19:56:35.956907 10017 net.cpp:1073] Copying source layer relu1
I0706 19:56:35.956979 10017 net.cpp:1073] Copying source layer ip2
I0706 19:56:35.957163 10017 net.cpp:1073] Copying source layer loss
I0706 19:56:35.957847 10017 cudnn_conv_layer.cpp:300] (n0.d0.r0) AllocateWorkspace trying to allocate 4194304 bytes for layer conv1
I0706 19:56:35.963382 10017 cudnn_conv_layer.cpp:300] (n0.d0.r0) AllocateWorkspace trying to allocate 4194304 bytes for layer conv2
I0706 19:56:35.974294 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.2
I0706 19:56:35.974567 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 2.33389 (* 1 = 2.33389 loss)
I0706 19:56:35.975054 10017 solver.cpp:241] Initial Test completed in 0.0193341s
I0706 19:56:35.977674 10048 internal_thread.cpp:48] Restarting 4 internal thread(s) on device 0
I0706 19:56:35.981096 10046 common.cpp:159] [0] Caffe instance 0x7fd9c13a5610 deleted, count 5, thread 10046
I0706 19:56:35.982612 10048 internal_thread.cpp:24] Starting 1 internal thread(s) on device 0
I0706 19:56:35.983234 10099 common.cpp:135] [0] New Caffe instance 0x7fd9c13a5610, count 6, thread 10099
I0706 19:56:35.983420 10099 common.cpp:194] New stream 0x7fd9ac000c40, device 0, thread 10099
I0706 19:56:35.986038 10099 internal_thread.cpp:85] Started internal thread 10099 on device 0, rank 0
I0706 19:56:35.986747 10048 internal_thread.cpp:19] InternalThread 10048: DataReader of local solver rank 0, parser threads 3, transf threads 4
I0706 19:56:35.986971 10048 data_reader.cpp:68] Data Reader threads: 3, out queues: 12, depth: 64
I0706 19:56:35.991454 10048 internal_thread.cpp:24] Starting 3 internal thread(s) on device 0
I0706 19:56:35.992589 10093 common.cpp:524] NVML initialized, thread 10093
I0706 19:56:35.992791 10104 common.cpp:135] [0] New Caffe instance 0x7fd98affd610, count 7, thread 10104
I0706 19:56:35.992988 10104 common.cpp:194] New stream 0x7fd984000c40, device 0, thread 10104
I0706 19:56:35.996383 10048 data_layer.cpp:199] [n0.d0.r0] Output data size: 64, 1, 28, 28
I0706 19:56:35.997108 10094 common.cpp:135] [0] New Caffe instance 0x7fd9917fe610, count 8, thread 10094
I0706 19:56:35.997128 10048 data_layer.cpp:105] [n0.d0.r0] Parser threads: 3 (auto)
I0706 19:56:35.997340 10104 internal_thread.cpp:85] Started internal thread 10104 on device 0, rank 0
I0706 19:56:35.997387 10048 data_layer.cpp:107] [n0.d0.r0] Transformer threads: 4 (auto)
I0706 19:56:35.997391 10094 common.cpp:194] New stream 0x7fd974000c40, device 0, thread 10094
I0706 19:56:35.997665 10104 db_lmdb.cpp:36] Opened lmdb examples/mnist/mnist_train_lmdb
I0706 19:56:36.000133 10094 internal_thread.cpp:85] Started internal thread 10094 on device 0, rank 0
I0706 19:56:36.000370 10106 common.cpp:135] [0] New Caffe instance 0x7fd989ffb610, count 9, thread 10106
I0706 19:56:36.000560 10106 common.cpp:194] New stream 0x7fd980000c40, device 0, thread 10106
I0706 19:56:36.003069 10106 internal_thread.cpp:85] Started internal thread 10106 on device 0, rank 0
I0706 19:56:36.003135 10096 common.cpp:135] [0] New Caffe instance 0x7fd98bfff610, count 10, thread 10096
I0706 19:56:36.003334 10106 db_lmdb.cpp:36] Opened lmdb examples/mnist/mnist_train_lmdb
I0706 19:56:36.003350 10096 common.cpp:194] New stream 0x7fd978000c40, device 0, thread 10096
I0706 19:56:36.006505 10096 internal_thread.cpp:85] Started internal thread 10096 on device 0, rank 0
I0706 19:56:36.006531 10105 common.cpp:135] [0] New Caffe instance 0x7fd98a7fc610, count 11, thread 10105
I0706 19:56:36.008548 10105 common.cpp:194] New stream 0x7fd97c000c40, device 0, thread 10105
I0706 19:56:36.010747 10105 internal_thread.cpp:85] Started internal thread 10105 on device 0, rank 0
I0706 19:56:36.010782 10097 common.cpp:135] [0] New Caffe instance 0x7fd98b7fe610, count 12, thread 10097
I0706 19:56:36.011003 10097 common.cpp:194] New stream 0x7fd96c000c40, device 0, thread 10097
I0706 19:56:36.011036 10105 db_lmdb.cpp:36] Opened lmdb examples/mnist/mnist_train_lmdb
I0706 19:56:36.012543 10094 blocking_queue.cpp:40] Waiting for datum
I0706 19:56:36.013036 10097 internal_thread.cpp:85] Started internal thread 10097 on device 0, rank 0
I0706 19:56:36.014111 10095 common.cpp:135] [0] New Caffe instance 0x7fd990ffd610, count 13, thread 10095
I0706 19:56:36.014314 10095 common.cpp:194] New stream 0x7fd964000c40, device 0, thread 10095
I0706 19:56:36.016469 10095 internal_thread.cpp:85] Started internal thread 10095 on device 0, rank 0
I0706 19:56:36.016518 10048 common.cpp:159] [0] Caffe instance 0x7fd9a7fff610 deleted, count 12, thread 10048
I0706 19:56:36.072829 10093 common.cpp:546] {0} NVML succeeded to set CPU affinity
I0706 19:56:36.073128 10093 common.cpp:135] [0] New Caffe instance 0x7fd991fff610, count 13, thread 10093
I0706 19:56:36.073338 10093 common.cpp:194] New stream 0x7fd98c008d30, device 0, thread 10093
I0706 19:56:36.073462 10099 common.cpp:546] {0} NVML succeeded to set CPU affinity
I0706 19:56:36.073590 10099 batch_transformer.cpp:57] Started BatchTransformer thread 10099
I0706 19:56:36.075884 10093 net.cpp:812] [0] Entering ReduceAndUpdate thread 10093
I0706 19:56:36.075955 10099 common.cpp:194] New stream 0x7fd9ac007960, device 0, thread 10099
I0706 19:56:36.076560 10099 common.cpp:194] New stream 0x7fd9ac008010, device 0, thread 10099
I0706 19:56:36.077595 10017 cudnn_conv_layer.cpp:300] [n0.d0.r0] AllocateWorkspace trying to allocate 4194304 bytes for layer conv1
I0706 19:56:36.082995 10017 cudnn_conv_layer.cpp:300] [n0.d0.r0] AllocateWorkspace trying to allocate 4194304 bytes for layer conv2
I0706 19:56:36.089864 10093 common.cpp:194] New stream 0x7fd98c002f00, device 0, thread 10093
I0706 19:56:36.092245 10093 common.cpp:194] New stream 0x7fd98c017e80, device 0, thread 10093
I0706 19:56:36.111685 10017 solver.cpp:342]     [0.0] Iteration 0 (0.135622 s), loss = 2.32973
I0706 19:56:36.111954 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 2.32973 (* 1 = 2.32973 loss)
I0706 19:56:36.112051 10017 sgd_solver.cpp:180] [0.0] Iteration 0, lr = 0.01, m = 0.9, lrm = 0.1, wd = 0.0005, gs = 1
I0706 19:56:36.127804 10017 solver.cpp:342]     [0.0] Iteration 1 (0.0160819 s), loss = 2.23151
I0706 19:56:36.128135 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 2.23151 (* 1 = 2.23151 loss)
I0706 19:56:36.129679 10017 cudnn_conv_layer.cpp:259] [n0.d0.r0] AllocateFindExWorkspace trying to allocate 978649088 bytes
I0706 19:56:36.177661 10017 cudnn_conv_layer.cpp:814] [n0.d0.r0] FindEx to release 978649088 bytes
I0706 19:56:36.186436 10017 cudnn_conv_layer.cpp:300] [n0.d0.r0] AllocateWorkspace trying to allocate 4194304 bytes for layer conv1
I0706 19:56:36.191289 10017 cudnn_conv_layer.cpp:859] [n0.d0.r0] Conv Algos (F,BD,BF): 'conv1' with space 4.19M 1/1 -> [3464 6888 0] 1 1 0 	(avail 1.58G, req 4.19M)	t: 0 0 0.88
I0706 19:56:36.193887 10017 cudnn_conv_layer.cpp:259] [n0.d0.r0] AllocateFindExWorkspace trying to allocate 978649088 bytes
I0706 19:56:36.359928 10017 cudnn_conv_layer.cpp:814] [n0.d0.r0] FindEx to release 978649088 bytes
I0706 19:56:36.370968 10017 cudnn_conv_layer.cpp:300] [n0.d0.r0] AllocateWorkspace trying to allocate 9776896 bytes for layer conv2
I0706 19:56:36.405678 10017 cudnn_conv_layer.cpp:859] [n0.d0.r0] Conv Algos (F,BD,BF): 'conv2' with space 9.78M 20/1 -> [392 9776800 3424] 1 2 3 	(avail 1.58G, req 9.78M)	t: 0 0.79 0.64
I0706 19:56:36.421023 10017 solver.cpp:342]     [0.0] Iteration 2 (0.293211 s), loss = 2.19266
I0706 19:56:36.421339 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 2.19266 (* 1 = 2.19266 loss)
I0706 19:56:37.363983 10017 solver.cpp:337]     [0.0] Iteration 100 (103.923 iter/s, 0.943002s/98 iter), loss = 0.287357
I0706 19:56:37.364332 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.287357 (* 1 = 0.287357 loss)
I0706 19:56:37.364437 10017 sgd_solver.cpp:180] [0.0] Iteration 100, lr = 0.00992565, m = 0.9, lrm = 0.0992565, wd = 0.0005, gs = 1
I0706 19:56:38.247653 10017 solver.cpp:337]     [0.0] Iteration 200 (113.159 iter/s, 0.883712s/100 iter), loss = 0.199149
I0706 19:56:38.247936 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.199149 (* 1 = 0.199149 loss)
I0706 19:56:38.248157 10017 sgd_solver.cpp:180] [0.0] Iteration 200, lr = 0.00985258, m = 0.9, lrm = 0.0985258, wd = 0.0005, gs = 1
I0706 19:56:39.213349 10017 solver.cpp:337]     [0.0] Iteration 300 (103.55 iter/s, 0.96572s/100 iter), loss = 0.0716317
I0706 19:56:39.213745 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0716317 (* 1 = 0.0716317 loss)
I0706 19:56:39.213904 10017 sgd_solver.cpp:180] [0.0] Iteration 300, lr = 0.00978075, m = 0.9, lrm = 0.0978075, wd = 0.0005, gs = 1
I0706 19:56:40.129657 10017 solver.cpp:337]     [0.0] Iteration 400 (109.131 iter/s, 0.916329s/100 iter), loss = 0.162225
I0706 19:56:40.130069 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.162225 (* 1 = 0.162225 loss)
I0706 19:56:40.130255 10017 sgd_solver.cpp:180] [0.0] Iteration 400, lr = 0.00971013, m = 0.9, lrm = 0.0971013, wd = 0.0005, gs = 1
I0706 19:56:41.018726 10017 solver.cpp:494] Iteration 500, Testing net (#0)
I0706 19:56:41.756098 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:56:41.785465 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9692
I0706 19:56:41.785759 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0934952 (* 1 = 0.0934952 loss)
I0706 19:56:41.786092 10017 solver.cpp:273] Tests completed in 1.65655s
I0706 19:56:41.794481 10017 solver.cpp:337]     [0.0] Iteration 500 (60.3663 iter/s, 1.65655s/100 iter), loss = 0.122976
I0706 19:56:41.794767 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.122976 (* 1 = 0.122976 loss)
I0706 19:56:41.794951 10017 sgd_solver.cpp:180] [0.0] Iteration 500, lr = 0.00964069, m = 0.9, lrm = 0.0964069, wd = 0.0005, gs = 1
I0706 19:56:42.677533 10017 solver.cpp:337]     [0.0] Iteration 600 (113.24 iter/s, 0.88308s/100 iter), loss = 0.227155
I0706 19:56:42.677829 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.227155 (* 1 = 0.227155 loss)
I0706 19:56:42.677947 10017 sgd_solver.cpp:180] [0.0] Iteration 600, lr = 0.0095724, m = 0.9, lrm = 0.0957239, wd = 0.0005, gs = 1
I0706 19:56:43.681578 10017 solver.cpp:337]     [0.0] Iteration 700 (99.5923 iter/s, 1.00409s/100 iter), loss = 0.111327
I0706 19:56:43.681900 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.111327 (* 1 = 0.111327 loss)
I0706 19:56:43.682004 10017 sgd_solver.cpp:180] [0.0] Iteration 700, lr = 0.00950522, m = 0.9, lrm = 0.0950522, wd = 0.0005, gs = 1
I0706 19:56:44.561580 10017 solver.cpp:337]     [0.0] Iteration 800 (113.637 iter/s, 0.879993s/100 iter), loss = 0.243262
I0706 19:56:44.561872 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.243262 (* 1 = 0.243262 loss)
I0706 19:56:44.561983 10017 sgd_solver.cpp:180] [0.0] Iteration 800, lr = 0.00943913, m = 0.9, lrm = 0.0943913, wd = 0.0005, gs = 1
I0706 19:56:45.438115 10017 solver.cpp:337]     [0.0] Iteration 900 (114.079 iter/s, 0.876582s/100 iter), loss = 0.0346556
I0706 19:56:45.438410 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0346557 (* 1 = 0.0346557 loss)
I0706 19:56:45.438514 10017 sgd_solver.cpp:180] [0.0] Iteration 900, lr = 0.00937411, m = 0.9, lrm = 0.0937411, wd = 0.0005, gs = 1
I0706 19:56:45.522413 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:56:46.348754 10017 solver.cpp:494] Iteration 1000, Testing net (#0)
I0706 19:56:47.225898 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:56:47.252414 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9798
I0706 19:56:47.252754 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0613429 (* 1 = 0.0613429 loss)
I0706 19:56:47.253043 10017 solver.cpp:273] Tests completed in 1.81508s
I0706 19:56:47.265813 10017 solver.cpp:337]     [0.0] Iteration 1000 (55.094 iter/s, 1.81508s/100 iter), 1.1/10.7ep, loss = 0.0271705
I0706 19:56:47.266156 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0271706 (* 1 = 0.0271706 loss)
I0706 19:56:47.266317 10017 sgd_solver.cpp:180] [0.0] Iteration 1000, lr = 0.00931012, m = 0.9, lrm = 0.0931012, wd = 0.0005, gs = 1
I0706 19:56:48.159806 10017 solver.cpp:337]     [0.0] Iteration 1100 (111.848 iter/s, 0.894069s/100 iter), 1.2/10.7ep, loss = 0.0194115
I0706 19:56:48.160137 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0194115 (* 1 = 0.0194115 loss)
I0706 19:56:48.160308 10017 sgd_solver.cpp:180] [0.0] Iteration 1100, lr = 0.00924715, m = 0.9, lrm = 0.0924714, wd = 0.0005, gs = 1
I0706 19:56:49.016124 10017 solver.cpp:337]     [0.0] Iteration 1200 (116.783 iter/s, 0.856287s/100 iter), 1.3/10.7ep, loss = 0.0254602
I0706 19:56:49.016402 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0254603 (* 1 = 0.0254603 loss)
I0706 19:56:49.016559 10017 sgd_solver.cpp:180] [0.0] Iteration 1200, lr = 0.00918515, m = 0.9, lrm = 0.0918515, wd = 0.0005, gs = 1
I0706 19:56:49.879714 10017 solver.cpp:337]     [0.0] Iteration 1300 (115.781 iter/s, 0.863696s/100 iter), 1.4/10.7ep, loss = 0.00600044
I0706 19:56:49.879958 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00600048 (* 1 = 0.00600048 loss)
I0706 19:56:49.880110 10017 sgd_solver.cpp:180] [0.0] Iteration 1300, lr = 0.00912412, m = 0.9, lrm = 0.0912412, wd = 0.0005, gs = 1
I0706 19:56:50.784595 10017 solver.cpp:337]     [0.0] Iteration 1400 (110.512 iter/s, 0.904878s/100 iter), 1.5/10.7ep, loss = 0.0635487
I0706 19:56:50.784940 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0635487 (* 1 = 0.0635487 loss)
I0706 19:56:50.785094 10017 sgd_solver.cpp:180] [0.0] Iteration 1400, lr = 0.00906403, m = 0.9, lrm = 0.0906403, wd = 0.0005, gs = 1
I0706 19:56:51.738320 10017 solver.cpp:494] Iteration 1500, Testing net (#0)
I0706 19:56:52.489637 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:56:52.512660 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9844
I0706 19:56:52.512946 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0490446 (* 1 = 0.0490446 loss)
I0706 19:56:52.513145 10017 solver.cpp:273] Tests completed in 1.72878s
I0706 19:56:52.523173 10017 solver.cpp:337]     [0.0] Iteration 1500 (57.8444 iter/s, 1.72878s/100 iter), 1.6/10.7ep, loss = 0.0407494
I0706 19:56:52.523459 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0407494 (* 1 = 0.0407494 loss)
I0706 19:56:52.523665 10017 sgd_solver.cpp:180] [0.0] Iteration 1500, lr = 0.00900485, m = 0.9, lrm = 0.0900485, wd = 0.0005, gs = 1
I0706 19:56:53.411176 10017 solver.cpp:337]     [0.0] Iteration 1600 (112.603 iter/s, 0.888079s/100 iter), 1.7/10.7ep, loss = 0.0720906
I0706 19:56:53.411459 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0720906 (* 1 = 0.0720906 loss)
I0706 19:56:53.411557 10017 sgd_solver.cpp:180] [0.0] Iteration 1600, lr = 0.00894657, m = 0.9, lrm = 0.0894657, wd = 0.0005, gs = 1
I0706 19:56:54.271517 10017 solver.cpp:337]     [0.0] Iteration 1700 (116.232 iter/s, 0.860348s/100 iter), 1.8/10.7ep, loss = 0.0313295
I0706 19:56:54.271854 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0313296 (* 1 = 0.0313296 loss)
I0706 19:56:54.272049 10017 sgd_solver.cpp:180] [0.0] Iteration 1700, lr = 0.00888916, m = 0.9, lrm = 0.0888916, wd = 0.0005, gs = 1
I0706 19:56:55.291779 10017 solver.cpp:337]     [0.0] Iteration 1800 (98.0157 iter/s, 1.02024s/100 iter), 1.9/10.7ep, loss = 0.0818504
I0706 19:56:55.292158 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0818504 (* 1 = 0.0818504 loss)
I0706 19:56:55.292384 10017 sgd_solver.cpp:180] [0.0] Iteration 1800, lr = 0.0088326, m = 0.9, lrm = 0.088326, wd = 0.0005, gs = 1
I0706 19:56:55.718135 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:56:56.182977 10017 solver.cpp:337]     [0.0] Iteration 1900 (112.194 iter/s, 0.891316s/100 iter), 2/10.7ep, loss = 0.0175831
I0706 19:56:56.183269 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0175831 (* 1 = 0.0175831 loss)
I0706 19:56:56.183382 10017 sgd_solver.cpp:180] [0.0] Iteration 1900, lr = 0.00877687, m = 0.9, lrm = 0.0877687, wd = 0.0005, gs = 1
I0706 19:56:57.063056 10017 solver.cpp:494] Iteration 2000, Testing net (#0)
I0706 19:56:57.854395 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:56:57.875313 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9857
I0706 19:56:57.875658 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0451327 (* 1 = 0.0451327 loss)
I0706 19:56:57.876005 10017 solver.cpp:273] Tests completed in 1.6932s
I0706 19:56:57.886417 10017 solver.cpp:337]     [0.0] Iteration 2000 (59.0596 iter/s, 1.6932s/100 iter), 2.1/10.7ep, loss = 0.108298
I0706 19:56:57.886687 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.108298 (* 1 = 0.108298 loss)
I0706 19:56:57.886826 10017 sgd_solver.cpp:180] [0.0] Iteration 2000, lr = 0.00872196, m = 0.9, lrm = 0.0872196, wd = 0.0005, gs = 1
I0706 19:56:58.825820 10017 solver.cpp:337]     [0.0] Iteration 2100 (106.45 iter/s, 0.939407s/100 iter), 2.2/10.7ep, loss = 0.0279649
I0706 19:56:58.826200 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0279649 (* 1 = 0.0279649 loss)
I0706 19:56:58.826393 10017 sgd_solver.cpp:180] [0.0] Iteration 2100, lr = 0.00866784, m = 0.9, lrm = 0.0866784, wd = 0.0005, gs = 1
I0706 19:56:59.794571 10017 solver.cpp:337]     [0.0] Iteration 2200 (103.222 iter/s, 0.968786s/100 iter), 2.3/10.7ep, loss = 0.0329568
I0706 19:56:59.795429 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0329568 (* 1 = 0.0329568 loss)
I0706 19:56:59.795640 10017 sgd_solver.cpp:180] [0.0] Iteration 2200, lr = 0.0086145, m = 0.9, lrm = 0.086145, wd = 0.0005, gs = 1
I0706 19:57:00.665479 10017 solver.cpp:337]     [0.0] Iteration 2300 (114.813 iter/s, 0.870983s/100 iter), 2.5/10.7ep, loss = 0.0107159
I0706 19:57:00.665813 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0107159 (* 1 = 0.0107159 loss)
I0706 19:57:00.665980 10017 sgd_solver.cpp:180] [0.0] Iteration 2300, lr = 0.00856192, m = 0.9, lrm = 0.0856192, wd = 0.0005, gs = 1
I0706 19:57:01.561069 10017 solver.cpp:337]     [0.0] Iteration 2400 (111.653 iter/s, 0.895632s/100 iter), 2.6/10.7ep, loss = 0.00804429
I0706 19:57:01.561326 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00804429 (* 1 = 0.00804429 loss)
I0706 19:57:01.561440 10017 sgd_solver.cpp:180] [0.0] Iteration 2400, lr = 0.00851008, m = 0.9, lrm = 0.0851008, wd = 0.0005, gs = 1
I0706 19:57:02.410867 10017 solver.cpp:494] Iteration 2500, Testing net (#0)
I0706 19:57:03.279178 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:03.306784 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.983
I0706 19:57:03.307145 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0537579 (* 1 = 0.0537579 loss)
I0706 19:57:03.307466 10017 solver.cpp:273] Tests completed in 1.74657s
I0706 19:57:03.319974 10017 solver.cpp:337]     [0.0] Iteration 2500 (57.255 iter/s, 1.74657s/100 iter), 2.7/10.7ep, loss = 0.0253638
I0706 19:57:03.320299 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0253638 (* 1 = 0.0253638 loss)
I0706 19:57:03.320448 10017 sgd_solver.cpp:180] [0.0] Iteration 2500, lr = 0.00845897, m = 0.9, lrm = 0.0845897, wd = 0.0005, gs = 1
I0706 19:57:04.224465 10017 solver.cpp:337]     [0.0] Iteration 2600 (110.555 iter/s, 0.904527s/100 iter), 2.8/10.7ep, loss = 0.00391196
I0706 19:57:04.224735 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00391193 (* 1 = 0.00391193 loss)
I0706 19:57:04.224879 10017 sgd_solver.cpp:180] [0.0] Iteration 2600, lr = 0.00840857, m = 0.9, lrm = 0.0840857, wd = 0.0005, gs = 1
I0706 19:57:05.101832 10017 solver.cpp:337]     [0.0] Iteration 2700 (113.981 iter/s, 0.877343s/100 iter), 2.9/10.7ep, loss = 0.0924725
I0706 19:57:05.102094 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0924725 (* 1 = 0.0924725 loss)
I0706 19:57:05.102197 10017 sgd_solver.cpp:180] [0.0] Iteration 2700, lr = 0.00835886, m = 0.9, lrm = 0.0835886, wd = 0.0005, gs = 1
I0706 19:57:05.865437 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:05.999938 10017 solver.cpp:337]     [0.0] Iteration 2800 (111.337 iter/s, 0.898177s/100 iter), 3/10.7ep, loss = 0.0116353
I0706 19:57:06.000258 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0116353 (* 1 = 0.0116353 loss)
I0706 19:57:06.000368 10017 sgd_solver.cpp:180] [0.0] Iteration 2800, lr = 0.00830984, m = 0.9, lrm = 0.0830984, wd = 0.0005, gs = 1
I0706 19:57:06.989604 10017 solver.cpp:337]     [0.0] Iteration 2900 (101.041 iter/s, 0.989701s/100 iter), 3.1/10.7ep, loss = 0.136267
I0706 19:57:06.989924 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.136267 (* 1 = 0.136267 loss)
I0706 19:57:06.990080 10017 sgd_solver.cpp:180] [0.0] Iteration 2900, lr = 0.00826148, m = 0.9, lrm = 0.0826148, wd = 0.0005, gs = 1
I0706 19:57:07.968681 10017 solver.cpp:494] Iteration 3000, Testing net (#0)
I0706 19:57:08.817536 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:08.841490 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9845
I0706 19:57:08.842087 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0477142 (* 1 = 0.0477142 loss)
I0706 19:57:08.842413 10017 solver.cpp:273] Tests completed in 1.85299s
I0706 19:57:08.852473 10017 solver.cpp:337]     [0.0] Iteration 3000 (53.9668 iter/s, 1.85299s/100 iter), 3.2/10.7ep, loss = 0.0280346
I0706 19:57:08.852777 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0280345 (* 1 = 0.0280345 loss)
I0706 19:57:08.852962 10017 sgd_solver.cpp:180] [0.0] Iteration 3000, lr = 0.00821377, m = 0.9, lrm = 0.0821377, wd = 0.0005, gs = 1
I0706 19:57:09.742661 10017 solver.cpp:337]     [0.0] Iteration 3100 (112.341 iter/s, 0.890145s/100 iter), 3.3/10.7ep, loss = 0.0155628
I0706 19:57:09.742972 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0155628 (* 1 = 0.0155628 loss)
I0706 19:57:09.743188 10017 sgd_solver.cpp:180] [0.0] Iteration 3100, lr = 0.0081667, m = 0.9, lrm = 0.081667, wd = 0.0005, gs = 1
I0706 19:57:10.618393 10017 solver.cpp:337]     [0.0] Iteration 3200 (114.184 iter/s, 0.875781s/100 iter), 3.4/10.7ep, loss = 0.00420886
I0706 19:57:10.618662 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00420877 (* 1 = 0.00420877 loss)
I0706 19:57:10.618769 10017 sgd_solver.cpp:180] [0.0] Iteration 3200, lr = 0.00812025, m = 0.9, lrm = 0.0812025, wd = 0.0005, gs = 1
I0706 19:57:11.691447 10017 solver.cpp:337]     [0.0] Iteration 3300 (93.1909 iter/s, 1.07307s/100 iter), 3.5/10.7ep, loss = 0.00712548
I0706 19:57:11.691795 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00712539 (* 1 = 0.00712539 loss)
I0706 19:57:11.691982 10017 sgd_solver.cpp:180] [0.0] Iteration 3300, lr = 0.00807442, m = 0.9, lrm = 0.0807442, wd = 0.0005, gs = 1
I0706 19:57:12.619364 10017 solver.cpp:337]     [0.0] Iteration 3400 (107.764 iter/s, 0.927956s/100 iter), 3.6/10.7ep, loss = 0.00580533
I0706 19:57:12.619665 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00580526 (* 1 = 0.00580526 loss)
I0706 19:57:12.619772 10017 sgd_solver.cpp:180] [0.0] Iteration 3400, lr = 0.00802918, m = 0.9, lrm = 0.0802918, wd = 0.0005, gs = 1
I0706 19:57:13.579285 10017 solver.cpp:494] Iteration 3500, Testing net (#0)
I0706 19:57:14.460692 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:14.493556 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9887
I0706 19:57:14.494040 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0390511 (* 1 = 0.0390511 loss)
I0706 19:57:14.494382 10017 solver.cpp:273] Tests completed in 1.8752s
I0706 19:57:14.507264 10017 solver.cpp:337]     [0.0] Iteration 3500 (53.3276 iter/s, 1.8752s/100 iter), 3.7/10.7ep, loss = 0.0286484
I0706 19:57:14.507573 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0286483 (* 1 = 0.0286483 loss)
I0706 19:57:14.507723 10017 sgd_solver.cpp:180] [0.0] Iteration 3500, lr = 0.00798454, m = 0.9, lrm = 0.0798453, wd = 0.0005, gs = 1
I0706 19:57:15.444757 10017 solver.cpp:337]     [0.0] Iteration 3600 (106.661 iter/s, 0.937554s/100 iter), 3.8/10.7ep, loss = 0.0317854
I0706 19:57:15.445147 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0317853 (* 1 = 0.0317853 loss)
I0706 19:57:15.445323 10017 sgd_solver.cpp:180] [0.0] Iteration 3600, lr = 0.00794046, m = 0.9, lrm = 0.0794046, wd = 0.0005, gs = 1
I0706 19:57:16.223234 10017 solver.cpp:337]     [0.0] Iteration 3700 (128.456 iter/s, 0.778478s/100 iter), 3.9/10.7ep, loss = 0.0211445
I0706 19:57:16.223532 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0211444 (* 1 = 0.0211444 loss)
I0706 19:57:16.223698 10017 sgd_solver.cpp:180] [0.0] Iteration 3700, lr = 0.00789695, m = 0.9, lrm = 0.0789695, wd = 0.0005, gs = 1
I0706 19:57:16.388348 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:17.016841 10017 solver.cpp:337]     [0.0] Iteration 3800 (126.002 iter/s, 0.793639s/100 iter), 4.1/10.7ep, loss = 0.0144993
I0706 19:57:17.017102 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0144992 (* 1 = 0.0144992 loss)
I0706 19:57:17.017207 10017 sgd_solver.cpp:180] [0.0] Iteration 3800, lr = 0.007854, m = 0.9, lrm = 0.0785399, wd = 0.0005, gs = 1
I0706 19:57:17.807824 10017 solver.cpp:337]     [0.0] Iteration 3900 (126.419 iter/s, 0.791017s/100 iter), 4.2/10.7ep, loss = 0.0401869
I0706 19:57:17.808115 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0401868 (* 1 = 0.0401868 loss)
I0706 19:57:17.808243 10017 sgd_solver.cpp:180] [0.0] Iteration 3900, lr = 0.00781158, m = 0.9, lrm = 0.0781158, wd = 0.0005, gs = 1
I0706 19:57:18.692370 10017 solver.cpp:494] Iteration 4000, Testing net (#0)
I0706 19:57:19.388569 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:19.406577 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9895
I0706 19:57:19.406824 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.033559 (* 1 = 0.033559 loss)
I0706 19:57:19.407040 10017 solver.cpp:273] Tests completed in 1.59938s
I0706 19:57:19.415279 10017 solver.cpp:337]     [0.0] Iteration 4000 (62.5241 iter/s, 1.59938s/100 iter), 4.3/10.7ep, loss = 0.00912536
I0706 19:57:19.415464 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00912529 (* 1 = 0.00912529 loss)
I0706 19:57:19.415558 10017 sgd_solver.cpp:180] [0.0] Iteration 4000, lr = 0.00776969, m = 0.9, lrm = 0.0776969, wd = 0.0005, gs = 1
I0706 19:57:20.223825 10017 solver.cpp:337]     [0.0] Iteration 4100 (123.683 iter/s, 0.808517s/100 iter), 4.4/10.7ep, loss = 0.00201252
I0706 19:57:20.224218 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00201246 (* 1 = 0.00201246 loss)
I0706 19:57:20.224463 10017 sgd_solver.cpp:180] [0.0] Iteration 4100, lr = 0.00772833, m = 0.9, lrm = 0.0772833, wd = 0.0005, gs = 1
I0706 19:57:21.035871 10017 solver.cpp:337]     [0.0] Iteration 4200 (123.138 iter/s, 0.812095s/100 iter), 4.5/10.7ep, loss = 0.00764767
I0706 19:57:21.036187 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00764762 (* 1 = 0.00764762 loss)
I0706 19:57:21.036327 10017 sgd_solver.cpp:180] [0.0] Iteration 4200, lr = 0.00768748, m = 0.9, lrm = 0.0768747, wd = 0.0005, gs = 1
I0706 19:57:21.778632 10017 solver.cpp:337]     [0.0] Iteration 4300 (134.628 iter/s, 0.74279s/100 iter), 4.6/10.7ep, loss = 0.0241676
I0706 19:57:21.778924 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0241676 (* 1 = 0.0241676 loss)
I0706 19:57:21.779050 10017 sgd_solver.cpp:180] [0.0] Iteration 4300, lr = 0.00764712, m = 0.9, lrm = 0.0764712, wd = 0.0005, gs = 1
I0706 19:57:22.534019 10017 solver.cpp:337]     [0.0] Iteration 4400 (132.378 iter/s, 0.755414s/100 iter), 4.7/10.7ep, loss = 0.00537901
I0706 19:57:22.534301 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00537899 (* 1 = 0.00537899 loss)
I0706 19:57:22.534458 10017 sgd_solver.cpp:180] [0.0] Iteration 4400, lr = 0.00760726, m = 0.9, lrm = 0.0760726, wd = 0.0005, gs = 1
I0706 19:57:23.375139 10017 solver.cpp:494] Iteration 4500, Testing net (#0)
I0706 19:57:24.158217 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:24.180860 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9869
I0706 19:57:24.181469 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0375278 (* 1 = 0.0375278 loss)
I0706 19:57:24.181839 10017 solver.cpp:273] Tests completed in 1.64798s
I0706 19:57:24.199160 10017 solver.cpp:337]     [0.0] Iteration 4500 (60.6802 iter/s, 1.64798s/100 iter), 4.8/10.7ep, loss = 0.00915532
I0706 19:57:24.199404 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00915529 (* 1 = 0.00915529 loss)
I0706 19:57:24.199506 10017 sgd_solver.cpp:180] [0.0] Iteration 4500, lr = 0.00756788, m = 0.9, lrm = 0.0756787, wd = 0.0005, gs = 1
I0706 19:57:25.164654 10017 solver.cpp:337]     [0.0] Iteration 4600 (103.569 iter/s, 0.965544s/100 iter), 4.9/10.7ep, loss = 0.00588717
I0706 19:57:25.164968 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00588713 (* 1 = 0.00588713 loss)
I0706 19:57:25.165120 10017 sgd_solver.cpp:180] [0.0] Iteration 4600, lr = 0.00752897, m = 0.9, lrm = 0.0752896, wd = 0.0005, gs = 1
I0706 19:57:25.801301 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:26.180258 10017 solver.cpp:337]     [0.0] Iteration 4700 (98.4595 iter/s, 1.01565s/100 iter), 5/10.7ep, loss = 0.0200379
I0706 19:57:26.180533 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0200379 (* 1 = 0.0200379 loss)
I0706 19:57:26.180634 10017 sgd_solver.cpp:180] [0.0] Iteration 4700, lr = 0.00749052, m = 0.9, lrm = 0.0749052, wd = 0.0005, gs = 1
I0706 19:57:27.129758 10017 solver.cpp:337]     [0.0] Iteration 4800 (105.314 iter/s, 0.949541s/100 iter), 5.1/10.7ep, loss = 0.00255296
I0706 19:57:27.130056 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00255295 (* 1 = 0.00255295 loss)
I0706 19:57:27.130180 10017 sgd_solver.cpp:180] [0.0] Iteration 4800, lr = 0.00745253, m = 0.9, lrm = 0.0745253, wd = 0.0005, gs = 1
I0706 19:57:28.185371 10017 solver.cpp:337]     [0.0] Iteration 4900 (94.7331 iter/s, 1.0556s/100 iter), 5.2/10.7ep, loss = 0.0192379
I0706 19:57:28.185762 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0192379 (* 1 = 0.0192379 loss)
I0706 19:57:28.185940 10017 sgd_solver.cpp:180] [0.0] Iteration 4900, lr = 0.00741498, m = 0.9, lrm = 0.0741498, wd = 0.0005, gs = 1
I0706 19:57:29.390235 10017 solver.cpp:763] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0706 19:57:29.390954 10017 net.cpp:1262] Serializing 9 layers
I0706 19:57:29.420439 10017 sgd_solver.cpp:419] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0706 19:57:29.434690 10017 solver.cpp:494] Iteration 5000, Testing net (#0)
I0706 19:57:30.453864 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:30.481168 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9892
I0706 19:57:30.481521 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0324197 (* 1 = 0.0324197 loss)
I0706 19:57:30.481803 10017 solver.cpp:273] Tests completed in 2.29668s
I0706 19:57:30.490437 10017 solver.cpp:337]     [0.0] Iteration 5000 (43.5412 iter/s, 2.29668s/100 iter), 5.3/10.7ep, loss = 0.00994717
I0706 19:57:30.490685 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00994716 (* 1 = 0.00994716 loss)
I0706 19:57:30.490793 10017 sgd_solver.cpp:180] [0.0] Iteration 5000, lr = 0.00737788, m = 0.9, lrm = 0.0737788, wd = 0.0005, gs = 1
I0706 19:57:31.281642 10017 solver.cpp:337]     [0.0] Iteration 5100 (126.385 iter/s, 0.791234s/100 iter), 5.4/10.7ep, loss = 0.0061926
I0706 19:57:31.281888 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00619258 (* 1 = 0.00619258 loss)
I0706 19:57:31.282022 10017 sgd_solver.cpp:180] [0.0] Iteration 5100, lr = 0.0073412, m = 0.9, lrm = 0.073412, wd = 0.0005, gs = 1
I0706 19:57:32.020314 10017 solver.cpp:337]     [0.0] Iteration 5200 (135.374 iter/s, 0.738695s/100 iter), 5.5/10.7ep, loss = 0.0207304
I0706 19:57:32.020612 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0207303 (* 1 = 0.0207303 loss)
I0706 19:57:32.020768 10017 sgd_solver.cpp:180] [0.0] Iteration 5200, lr = 0.00730495, m = 0.9, lrm = 0.0730495, wd = 0.0005, gs = 1
I0706 19:57:32.823493 10017 solver.cpp:337]     [0.0] Iteration 5300 (124.503 iter/s, 0.803196s/100 iter), 5.7/10.7ep, loss = 0.0186783
I0706 19:57:32.824014 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0186782 (* 1 = 0.0186782 loss)
I0706 19:57:32.824329 10017 sgd_solver.cpp:180] [0.0] Iteration 5300, lr = 0.00726911, m = 0.9, lrm = 0.0726911, wd = 0.0005, gs = 1
I0706 19:57:33.683784 10017 solver.cpp:337]     [0.0] Iteration 5400 (116.237 iter/s, 0.860314s/100 iter), 5.8/10.7ep, loss = 0.0071339
I0706 19:57:33.684160 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00713387 (* 1 = 0.00713387 loss)
I0706 19:57:33.684334 10017 sgd_solver.cpp:180] [0.0] Iteration 5400, lr = 0.00723368, m = 0.9, lrm = 0.0723368, wd = 0.0005, gs = 1
I0706 19:57:34.481745 10017 solver.cpp:494] Iteration 5500, Testing net (#0)
I0706 19:57:35.318354 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:35.337049 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.989
I0706 19:57:35.337342 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0328522 (* 1 = 0.0328522 loss)
I0706 19:57:35.337605 10017 solver.cpp:273] Tests completed in 1.654s
I0706 19:57:35.345316 10017 solver.cpp:337]     [0.0] Iteration 5500 (60.4595 iter/s, 1.654s/100 iter), 5.9/10.7ep, loss = 0.00385399
I0706 19:57:35.345577 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00385397 (* 1 = 0.00385397 loss)
I0706 19:57:35.346029 10017 sgd_solver.cpp:180] [0.0] Iteration 5500, lr = 0.00719865, m = 0.9, lrm = 0.0719865, wd = 0.0005, gs = 1
I0706 19:57:36.314460 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:36.365653 10017 solver.cpp:337]     [0.0] Iteration 5600 (98.01 iter/s, 1.0203s/100 iter), 6/10.7ep, loss = 0.00577793
I0706 19:57:36.366029 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00577791 (* 1 = 0.00577791 loss)
I0706 19:57:36.366235 10017 sgd_solver.cpp:180] [0.0] Iteration 5600, lr = 0.00716402, m = 0.9, lrm = 0.0716401, wd = 0.0005, gs = 1
I0706 19:57:37.345785 10017 solver.cpp:337]     [0.0] Iteration 5700 (102.021 iter/s, 0.980193s/100 iter), 6.1/10.7ep, loss = 0.0172235
I0706 19:57:37.346086 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0172235 (* 1 = 0.0172235 loss)
I0706 19:57:37.346194 10017 sgd_solver.cpp:180] [0.0] Iteration 5700, lr = 0.00712977, m = 0.9, lrm = 0.0712976, wd = 0.0005, gs = 1
I0706 19:57:38.274602 10017 solver.cpp:337]     [0.0] Iteration 5800 (107.66 iter/s, 0.92885s/100 iter), 6.2/10.7ep, loss = 0.00356235
I0706 19:57:38.274925 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00356234 (* 1 = 0.00356234 loss)
I0706 19:57:38.275174 10017 sgd_solver.cpp:180] [0.0] Iteration 5800, lr = 0.0070959, m = 0.9, lrm = 0.0709589, wd = 0.0005, gs = 1
I0706 19:57:39.263245 10017 solver.cpp:337]     [0.0] Iteration 5900 (101.214 iter/s, 0.988004s/100 iter), 6.3/10.7ep, loss = 0.00355962
I0706 19:57:39.263615 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00355962 (* 1 = 0.00355962 loss)
I0706 19:57:39.263777 10017 sgd_solver.cpp:180] [0.0] Iteration 5900, lr = 0.0070624, m = 0.9, lrm = 0.070624, wd = 0.0005, gs = 1
I0706 19:57:40.284862 10017 solver.cpp:494] Iteration 6000, Testing net (#0)
I0706 19:57:41.237918 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:41.264479 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9904
I0706 19:57:41.264982 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0296469 (* 1 = 0.0296469 loss)
I0706 19:57:41.265614 10017 solver.cpp:273] Tests completed in 2.00256s
I0706 19:57:41.277338 10017 solver.cpp:337]     [0.0] Iteration 6000 (49.9362 iter/s, 2.00256s/100 iter), 6.4/10.7ep, loss = 0.00271161
I0706 19:57:41.277611 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0027116 (* 1 = 0.0027116 loss)
I0706 19:57:41.277755 10017 sgd_solver.cpp:180] [0.0] Iteration 6000, lr = 0.00702927, m = 0.9, lrm = 0.0702927, wd = 0.0005, gs = 1
I0706 19:57:42.135021 10017 solver.cpp:337]     [0.0] Iteration 6100 (116.592 iter/s, 0.857693s/100 iter), 6.5/10.7ep, loss = 0.00288805
I0706 19:57:42.135321 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00288803 (* 1 = 0.00288803 loss)
I0706 19:57:42.135493 10017 sgd_solver.cpp:180] [0.0] Iteration 6100, lr = 0.0069965, m = 0.9, lrm = 0.0699649, wd = 0.0005, gs = 1
I0706 19:57:42.942210 10017 solver.cpp:337]     [0.0] Iteration 6200 (123.885 iter/s, 0.8072s/100 iter), 6.6/10.7ep, loss = 0.00610623
I0706 19:57:42.942541 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00610622 (* 1 = 0.00610622 loss)
I0706 19:57:42.942701 10017 sgd_solver.cpp:180] [0.0] Iteration 6200, lr = 0.00696408, m = 0.9, lrm = 0.0696408, wd = 0.0005, gs = 1
I0706 19:57:43.706079 10017 solver.cpp:337]     [0.0] Iteration 6300 (130.905 iter/s, 0.763915s/100 iter), 6.7/10.7ep, loss = 0.015303
I0706 19:57:43.706343 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0153029 (* 1 = 0.0153029 loss)
I0706 19:57:43.706449 10017 sgd_solver.cpp:180] [0.0] Iteration 6300, lr = 0.00693201, m = 0.9, lrm = 0.0693201, wd = 0.0005, gs = 1
I0706 19:57:44.482369 10017 solver.cpp:337]     [0.0] Iteration 6400 (128.813 iter/s, 0.776318s/100 iter), 6.8/10.7ep, loss = 0.00142716
I0706 19:57:44.482625 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00142715 (* 1 = 0.00142715 loss)
I0706 19:57:44.482734 10017 sgd_solver.cpp:180] [0.0] Iteration 6400, lr = 0.00690029, m = 0.9, lrm = 0.0690028, wd = 0.0005, gs = 1
I0706 19:57:45.366185 10017 solver.cpp:494] Iteration 6500, Testing net (#0)
I0706 19:57:46.121671 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:46.140821 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9893
I0706 19:57:46.141144 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0321152 (* 1 = 0.0321152 loss)
I0706 19:57:46.141450 10017 solver.cpp:273] Tests completed in 1.65924s
I0706 19:57:46.150185 10017 solver.cpp:337]     [0.0] Iteration 6500 (60.2687 iter/s, 1.65924s/100 iter), 6.9/10.7ep, loss = 0.00303027
I0706 19:57:46.150374 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00303027 (* 1 = 0.00303027 loss)
I0706 19:57:46.150467 10017 sgd_solver.cpp:180] [0.0] Iteration 6500, lr = 0.0068689, m = 0.9, lrm = 0.068689, wd = 0.0005, gs = 1
I0706 19:57:46.438251 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:47.011055 10017 solver.cpp:337]     [0.0] Iteration 6600 (116.159 iter/s, 0.860886s/100 iter), 7/10.7ep, loss = 0.0143828
I0706 19:57:47.011335 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0143828 (* 1 = 0.0143828 loss)
I0706 19:57:47.011579 10017 sgd_solver.cpp:180] [0.0] Iteration 6600, lr = 0.00683784, m = 0.9, lrm = 0.0683784, wd = 0.0005, gs = 1
I0706 19:57:47.845309 10017 solver.cpp:337]     [0.0] Iteration 6700 (119.863 iter/s, 0.834286s/100 iter), 7.1/10.7ep, loss = 0.0284851
I0706 19:57:47.845564 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0284851 (* 1 = 0.0284851 loss)
I0706 19:57:47.845667 10017 sgd_solver.cpp:180] [0.0] Iteration 6700, lr = 0.00680711, m = 0.9, lrm = 0.0680711, wd = 0.0005, gs = 1
I0706 19:57:48.626771 10017 solver.cpp:337]     [0.0] Iteration 6800 (127.962 iter/s, 0.78148s/100 iter), 7.3/10.7ep, loss = 0.00301668
I0706 19:57:48.627091 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00301667 (* 1 = 0.00301667 loss)
I0706 19:57:48.627197 10017 sgd_solver.cpp:180] [0.0] Iteration 6800, lr = 0.0067767, m = 0.9, lrm = 0.0677669, wd = 0.0005, gs = 1
I0706 19:57:49.392537 10017 solver.cpp:337]     [0.0] Iteration 6900 (130.594 iter/s, 0.765731s/100 iter), 7.4/10.7ep, loss = 0.00791351
I0706 19:57:49.392805 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0079135 (* 1 = 0.0079135 loss)
I0706 19:57:49.392908 10017 sgd_solver.cpp:180] [0.0] Iteration 6900, lr = 0.0067466, m = 0.9, lrm = 0.067466, wd = 0.0005, gs = 1
I0706 19:57:50.186730 10017 solver.cpp:494] Iteration 7000, Testing net (#0)
I0706 19:57:50.922780 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:50.940202 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9899
I0706 19:57:50.940457 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0308752 (* 1 = 0.0308752 loss)
I0706 19:57:50.940719 10017 solver.cpp:273] Tests completed in 1.54838s
I0706 19:57:50.949417 10017 solver.cpp:337]     [0.0] Iteration 7000 (64.5836 iter/s, 1.54838s/100 iter), 7.5/10.7ep, loss = 0.00218929
I0706 19:57:50.949613 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00218928 (* 1 = 0.00218928 loss)
I0706 19:57:50.949707 10017 sgd_solver.cpp:180] [0.0] Iteration 7000, lr = 0.00671681, m = 0.9, lrm = 0.0671681, wd = 0.0005, gs = 1
I0706 19:57:51.728955 10017 solver.cpp:337]     [0.0] Iteration 7100 (128.282 iter/s, 0.779533s/100 iter), 7.6/10.7ep, loss = 0.00359288
I0706 19:57:51.729236 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00359288 (* 1 = 0.00359288 loss)
I0706 19:57:51.729341 10017 sgd_solver.cpp:180] [0.0] Iteration 7100, lr = 0.00668733, m = 0.9, lrm = 0.0668733, wd = 0.0005, gs = 1
I0706 19:57:52.533294 10017 solver.cpp:337]     [0.0] Iteration 7200 (124.322 iter/s, 0.804363s/100 iter), 7.7/10.7ep, loss = 0.0160567
I0706 19:57:52.533658 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0160567 (* 1 = 0.0160567 loss)
I0706 19:57:52.533764 10017 sgd_solver.cpp:180] [0.0] Iteration 7200, lr = 0.00665815, m = 0.9, lrm = 0.0665815, wd = 0.0005, gs = 1
I0706 19:57:53.345788 10017 solver.cpp:337]     [0.0] Iteration 7300 (123.075 iter/s, 0.812512s/100 iter), 7.8/10.7ep, loss = 0.0220648
I0706 19:57:53.346060 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0220648 (* 1 = 0.0220648 loss)
I0706 19:57:53.346223 10017 sgd_solver.cpp:180] [0.0] Iteration 7300, lr = 0.00662927, m = 0.9, lrm = 0.0662926, wd = 0.0005, gs = 1
I0706 19:57:54.136193 10017 solver.cpp:337]     [0.0] Iteration 7400 (126.524 iter/s, 0.790364s/100 iter), 7.9/10.7ep, loss = 0.0210898
I0706 19:57:54.136502 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0210898 (* 1 = 0.0210898 loss)
I0706 19:57:54.136669 10017 sgd_solver.cpp:180] [0.0] Iteration 7400, lr = 0.00660067, m = 0.9, lrm = 0.0660067, wd = 0.0005, gs = 1
I0706 19:57:54.753779 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:54.962940 10017 solver.cpp:494] Iteration 7500, Testing net (#0)
I0706 19:57:55.742884 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:57:55.769033 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9903
I0706 19:57:55.769340 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0323387 (* 1 = 0.0323387 loss)
I0706 19:57:55.769709 10017 solver.cpp:273] Tests completed in 1.63374s
I0706 19:57:55.778321 10017 solver.cpp:337]     [0.0] Iteration 7500 (61.2092 iter/s, 1.63374s/100 iter), 8/10.7ep, loss = 0.0017849
I0706 19:57:55.778563 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00178489 (* 1 = 0.00178489 loss)
I0706 19:57:55.778704 10017 sgd_solver.cpp:180] [0.0] Iteration 7500, lr = 0.00657236, m = 0.9, lrm = 0.0657236, wd = 0.0005, gs = 1
I0706 19:57:56.655948 10017 solver.cpp:337]     [0.0] Iteration 7600 (113.987 iter/s, 0.877294s/100 iter), 8.1/10.7ep, loss = 0.000862317
I0706 19:57:56.656416 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.000862305 (* 1 = 0.000862305 loss)
I0706 19:57:56.656637 10017 sgd_solver.cpp:180] [0.0] Iteration 7600, lr = 0.00654433, m = 0.9, lrm = 0.0654433, wd = 0.0005, gs = 1
I0706 19:57:57.696256 10017 solver.cpp:337]     [0.0] Iteration 7700 (96.1169 iter/s, 1.0404s/100 iter), 8.2/10.7ep, loss = 0.00224367
I0706 19:57:57.696528 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00224365 (* 1 = 0.00224365 loss)
I0706 19:57:57.696643 10017 sgd_solver.cpp:180] [0.0] Iteration 7700, lr = 0.00651658, m = 0.9, lrm = 0.0651658, wd = 0.0005, gs = 1
I0706 19:57:58.548032 10017 solver.cpp:337]     [0.0] Iteration 7800 (117.398 iter/s, 0.851803s/100 iter), 8.3/10.7ep, loss = 0.00528347
I0706 19:57:58.548354 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00528346 (* 1 = 0.00528346 loss)
I0706 19:57:58.548457 10017 sgd_solver.cpp:180] [0.0] Iteration 7800, lr = 0.00648911, m = 0.9, lrm = 0.0648911, wd = 0.0005, gs = 1
I0706 19:57:59.346415 10017 solver.cpp:337]     [0.0] Iteration 7900 (125.25 iter/s, 0.798406s/100 iter), 8.4/10.7ep, loss = 0.0173786
I0706 19:57:59.346698 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0173786 (* 1 = 0.0173786 loss)
I0706 19:57:59.346799 10017 sgd_solver.cpp:180] [0.0] Iteration 7900, lr = 0.0064619, m = 0.9, lrm = 0.064619, wd = 0.0005, gs = 1
I0706 19:58:00.243144 10017 solver.cpp:494] Iteration 8000, Testing net (#0)
I0706 19:58:01.047380 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:01.075350 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9906
I0706 19:58:01.075635 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0298968 (* 1 = 0.0298968 loss)
I0706 19:58:01.075847 10017 solver.cpp:273] Tests completed in 1.72961s
I0706 19:58:01.085112 10017 solver.cpp:337]     [0.0] Iteration 8000 (57.8166 iter/s, 1.72961s/100 iter), 8.5/10.7ep, loss = 0.00531212
I0706 19:58:01.085454 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00531211 (* 1 = 0.00531211 loss)
I0706 19:58:01.085609 10017 sgd_solver.cpp:180] [0.0] Iteration 8000, lr = 0.00643496, m = 0.9, lrm = 0.0643495, wd = 0.0005, gs = 1
I0706 19:58:02.116602 10017 solver.cpp:337]     [0.0] Iteration 8100 (96.9445 iter/s, 1.03152s/100 iter), 8.6/10.7ep, loss = 0.00993956
I0706 19:58:02.116875 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00993955 (* 1 = 0.00993955 loss)
I0706 19:58:02.117012 10017 sgd_solver.cpp:180] [0.0] Iteration 8100, lr = 0.00640827, m = 0.9, lrm = 0.0640827, wd = 0.0005, gs = 1
I0706 19:58:03.042055 10017 solver.cpp:337]     [0.0] Iteration 8200 (108.05 iter/s, 0.9255s/100 iter), 8.7/10.7ep, loss = 0.00336121
I0706 19:58:03.042330 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0033612 (* 1 = 0.0033612 loss)
I0706 19:58:03.042492 10017 sgd_solver.cpp:180] [0.0] Iteration 8200, lr = 0.00638185, m = 0.9, lrm = 0.0638185, wd = 0.0005, gs = 1
I0706 19:58:03.931592 10017 solver.cpp:337]     [0.0] Iteration 8300 (112.415 iter/s, 0.889563s/100 iter), 8.9/10.7ep, loss = 0.0222998
I0706 19:58:03.931854 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0222998 (* 1 = 0.0222998 loss)
I0706 19:58:03.931960 10017 sgd_solver.cpp:180] [0.0] Iteration 8300, lr = 0.00635568, m = 0.9, lrm = 0.0635567, wd = 0.0005, gs = 1
I0706 19:58:04.876730 10017 solver.cpp:337]     [0.0] Iteration 8400 (105.801 iter/s, 0.945168s/100 iter), 9/10.7ep, loss = 0.00185629
I0706 19:58:04.877291 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00185627 (* 1 = 0.00185627 loss)
I0706 19:58:04.877425 10017 sgd_solver.cpp:180] [0.0] Iteration 8400, lr = 0.00632975, m = 0.9, lrm = 0.0632975, wd = 0.0005, gs = 1
I0706 19:58:04.955363 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:05.663807 10017 solver.cpp:494] Iteration 8500, Testing net (#0)
I0706 19:58:06.405843 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:06.424494 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9901
I0706 19:58:06.424878 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0308619 (* 1 = 0.0308619 loss)
I0706 19:58:06.425189 10017 solver.cpp:273] Tests completed in 1.5486s
I0706 19:58:06.435140 10017 solver.cpp:337]     [0.0] Iteration 8500 (64.5743 iter/s, 1.5486s/100 iter), 9.1/10.7ep, loss = 0.00225594
I0706 19:58:06.435420 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00225592 (* 1 = 0.00225592 loss)
I0706 19:58:06.435521 10017 sgd_solver.cpp:180] [0.0] Iteration 8500, lr = 0.00630407, m = 0.9, lrm = 0.0630407, wd = 0.0005, gs = 1
I0706 19:58:07.244632 10017 solver.cpp:337]     [0.0] Iteration 8600 (123.533 iter/s, 0.809502s/100 iter), 9.2/10.7ep, loss = 0.000522125
I0706 19:58:07.244894 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.000522105 (* 1 = 0.000522105 loss)
I0706 19:58:07.245000 10017 sgd_solver.cpp:180] [0.0] Iteration 8600, lr = 0.00627864, m = 0.9, lrm = 0.0627863, wd = 0.0005, gs = 1
I0706 19:58:08.036646 10017 solver.cpp:337]     [0.0] Iteration 8700 (126.258 iter/s, 0.792029s/100 iter), 9.3/10.7ep, loss = 0.0294049
I0706 19:58:08.036898 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.0294048 (* 1 = 0.0294048 loss)
I0706 19:58:08.036999 10017 sgd_solver.cpp:180] [0.0] Iteration 8700, lr = 0.00625344, m = 0.9, lrm = 0.0625344, wd = 0.0005, gs = 1
I0706 19:58:08.835359 10017 solver.cpp:337]     [0.0] Iteration 8800 (125.198 iter/s, 0.798733s/100 iter), 9.4/10.7ep, loss = 0.00114956
I0706 19:58:08.835618 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00114954 (* 1 = 0.00114954 loss)
I0706 19:58:08.835800 10017 sgd_solver.cpp:180] [0.0] Iteration 8800, lr = 0.00622847, m = 0.9, lrm = 0.0622847, wd = 0.0005, gs = 1
I0706 19:58:09.690376 10017 solver.cpp:337]     [0.0] Iteration 8900 (117.021 iter/s, 0.85455s/100 iter), 9.5/10.7ep, loss = 0.00346491
I0706 19:58:09.690697 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00346489 (* 1 = 0.00346489 loss)
I0706 19:58:09.690804 10017 sgd_solver.cpp:180] [0.0] Iteration 8900, lr = 0.00620374, m = 0.9, lrm = 0.0620374, wd = 0.0005, gs = 1
I0706 19:58:10.637796 10017 solver.cpp:494] Iteration 9000, Testing net (#0)
I0706 19:58:11.366525 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:11.390123 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9901
I0706 19:58:11.390444 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0300149 (* 1 = 0.0300149 loss)
I0706 19:58:11.390746 10017 solver.cpp:273] Tests completed in 1.70054s
I0706 19:58:11.399889 10017 solver.cpp:337]     [0.0] Iteration 9000 (58.8049 iter/s, 1.70054s/100 iter), 9.6/10.7ep, loss = 0.00729367
I0706 19:58:11.400218 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00729364 (* 1 = 0.00729364 loss)
I0706 19:58:11.400379 10017 sgd_solver.cpp:180] [0.0] Iteration 9000, lr = 0.00617924, m = 0.9, lrm = 0.0617923, wd = 0.0005, gs = 1
I0706 19:58:12.362208 10017 solver.cpp:337]     [0.0] Iteration 9100 (103.912 iter/s, 0.962357s/100 iter), 9.7/10.7ep, loss = 0.00659918
I0706 19:58:12.362474 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00659915 (* 1 = 0.00659915 loss)
I0706 19:58:12.362593 10017 sgd_solver.cpp:180] [0.0] Iteration 9100, lr = 0.00615496, m = 0.9, lrm = 0.0615495, wd = 0.0005, gs = 1
I0706 19:58:13.187798 10017 solver.cpp:337]     [0.0] Iteration 9200 (121.125 iter/s, 0.825591s/100 iter), 9.8/10.7ep, loss = 0.0019535
I0706 19:58:13.188174 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00195346 (* 1 = 0.00195346 loss)
I0706 19:58:13.188344 10017 sgd_solver.cpp:180] [0.0] Iteration 9200, lr = 0.0061309, m = 0.9, lrm = 0.061309, wd = 0.0005, gs = 1
I0706 19:58:13.975594 10017 solver.cpp:337]     [0.0] Iteration 9300 (126.931 iter/s, 0.787828s/100 iter), 9.9/10.7ep, loss = 0.0021685
I0706 19:58:13.975876 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00216847 (* 1 = 0.00216847 loss)
I0706 19:58:13.975978 10017 sgd_solver.cpp:180] [0.0] Iteration 9300, lr = 0.00610706, m = 0.9, lrm = 0.0610706, wd = 0.0005, gs = 1
I0706 19:58:14.352010 10104 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:14.763345 10017 solver.cpp:337]     [0.0] Iteration 9400 (126.941 iter/s, 0.78777s/100 iter), 10/10.7ep, loss = 0.00268299
I0706 19:58:14.763636 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00268295 (* 1 = 0.00268295 loss)
I0706 19:58:14.763773 10017 sgd_solver.cpp:180] [0.0] Iteration 9400, lr = 0.00608343, m = 0.9, lrm = 0.0608343, wd = 0.0005, gs = 1
I0706 19:58:15.541426 10017 solver.cpp:494] Iteration 9500, Testing net (#0)
I0706 19:58:16.345624 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:16.363692 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9887
I0706 19:58:16.363961 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0362707 (* 1 = 0.0362707 loss)
I0706 19:58:16.364300 10017 solver.cpp:273] Tests completed in 1.6011s
I0706 19:58:16.371852 10017 solver.cpp:337]     [0.0] Iteration 9500 (62.457 iter/s, 1.6011s/100 iter), 10.1/10.7ep, loss = 0.0118641
I0706 19:58:16.372146 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.011864 (* 1 = 0.011864 loss)
I0706 19:58:16.372299 10017 sgd_solver.cpp:180] [0.0] Iteration 9500, lr = 0.00606002, m = 0.9, lrm = 0.0606002, wd = 0.0005, gs = 1
I0706 19:58:17.146908 10017 solver.cpp:337]     [0.0] Iteration 9600 (129.024 iter/s, 0.775048s/100 iter), 10.2/10.7ep, loss = 0.00463199
I0706 19:58:17.147171 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00463195 (* 1 = 0.00463195 loss)
I0706 19:58:17.147370 10017 sgd_solver.cpp:180] [0.0] Iteration 9600, lr = 0.00603682, m = 0.9, lrm = 0.0603681, wd = 0.0005, gs = 1
I0706 19:58:17.918742 10017 solver.cpp:337]     [0.0] Iteration 9700 (129.563 iter/s, 0.771823s/100 iter), 10.3/10.7ep, loss = 0.00492238
I0706 19:58:17.919103 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00492235 (* 1 = 0.00492235 loss)
I0706 19:58:17.919314 10017 sgd_solver.cpp:180] [0.0] Iteration 9700, lr = 0.00601382, m = 0.9, lrm = 0.0601382, wd = 0.0005, gs = 1
I0706 19:58:18.702513 10017 solver.cpp:337]     [0.0] Iteration 9800 (127.59 iter/s, 0.783759s/100 iter), 10.5/10.7ep, loss = 0.00406752
I0706 19:58:18.702841 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00406748 (* 1 = 0.00406748 loss)
I0706 19:58:18.702956 10017 sgd_solver.cpp:180] [0.0] Iteration 9800, lr = 0.00599102, m = 0.9, lrm = 0.0599102, wd = 0.0005, gs = 1
I0706 19:58:19.513661 10017 solver.cpp:337]     [0.0] Iteration 9900 (123.278 iter/s, 0.811176s/100 iter), 10.6/10.7ep, loss = 0.000588764
I0706 19:58:19.514060 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.000588734 (* 1 = 0.000588734 loss)
I0706 19:58:19.514221 10017 sgd_solver.cpp:180] [0.0] Iteration 9900, lr = 0.00596843, m = 0.9, lrm = 0.0596843, wd = 0.0005, gs = 1
I0706 19:58:20.358317 10017 solver.cpp:337]     [0.0] Iteration 10000 (117.205 iter/s, 0.844677s/99 iter), 10.7/10.7ep, loss = 0.0044502
I0706 19:58:20.358592 10017 solver.cpp:358]     [0.0]     Train net output #0: loss = 0.00445017 (* 1 = 0.00445017 loss)
I0706 19:58:20.358759 10017 solver.cpp:763] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0706 19:58:20.358875 10017 net.cpp:1262] Serializing 9 layers
I0706 19:58:20.375291 10017 sgd_solver.cpp:419] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0706 19:58:20.386749 10093 net.cpp:927] [0.0] Leaving ReduceAndUpdate thread 10093
I0706 19:58:20.387079 10093 common.cpp:159] [0] Caffe instance 0x7fd991fff610 deleted, count 12, thread 10093
I0706 19:58:20.392877 10017 solver.cpp:459] Iteration 10000, loss = 0.000631805
I0706 19:58:20.393087 10017 solver.cpp:494] Iteration 10000, Testing net (#0)
I0706 19:58:21.130911 10086 data_reader.cpp:330] Restarting data pre-fetching
I0706 19:58:21.156584 10017 solver.cpp:581]     (0.0)    Test net output #0: accuracy = 0.9898
I0706 19:58:21.156935 10017 solver.cpp:581]     (0.0)    Test net output #1: loss = 0.0297811 (* 1 = 0.0297811 loss)
I0706 19:58:21.157397 10017 caffe.cpp:258] Solver performance on device 0: 96.37 * 64 = 6168 img/sec (10000 itr in 103.7 sec)
I0706 19:58:21.157506 10017 caffe.cpp:262] Optimization Done in 1m 52s
I0706 19:58:21.167817 10087 common.cpp:159] [0] Caffe instance 0x7fd9a4c7d610 deleted, count 11, thread 10087
I0706 19:58:21.172861 10086 common.cpp:159] [0] Caffe instance 0x7fd9a647e610 deleted, count 10, thread 10086
I0706 19:58:21.174314 10085 common.cpp:159] [0] Caffe instance 0x7fd9a77fe610 deleted, count 9, thread 10085
I0706 19:58:21.182822 10095 common.cpp:159] [0] Caffe instance 0x7fd990ffd610 deleted, count 8, thread 10095
I0706 19:58:21.183199 10096 common.cpp:159] [0] Caffe instance 0x7fd98bfff610 deleted, count 7, thread 10096
I0706 19:58:21.183665 10097 common.cpp:159] [0] Caffe instance 0x7fd98b7fe610 deleted, count 6, thread 10097
I0706 19:58:21.184031 10094 common.cpp:159] [0] Caffe instance 0x7fd9917fe610 deleted, count 5, thread 10094
I0706 19:58:21.205701 10106 common.cpp:159] [0] Caffe instance 0x7fd989ffb610 deleted, count 4, thread 10106
I0706 19:58:21.206048 10104 common.cpp:159] [0] Caffe instance 0x7fd98affd610 deleted, count 3, thread 10104
I0706 19:58:21.206413 10105 common.cpp:159] [0] Caffe instance 0x7fd98a7fc610 deleted, count 2, thread 10105
I0706 19:58:21.208763 10099 common.cpp:159] [0] Caffe instance 0x7fd9c13a5610 deleted, count 1, thread 10099
I0706 19:58:21.226588 10017 common.cpp:159] [0] Caffe instance 0x7fd9e5997750 deleted, count 0, thread 10017
